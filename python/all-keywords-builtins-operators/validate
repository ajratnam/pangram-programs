#!/usr/bin/env python3
import unittest
import keyword
import operator
import re
import tokenize
from io import StringIO  # Python 3


PANGRAM_FILE="pangram.py"


####################################################################################################

# Being constructing a list of all unique and valid Python source lexemes in string form

python_lexemes = set()

# Get keywords, i.e. reserved words
for kw in keyword.kwlist:
	python_lexemes.add(kw)

# Get builtin function names like "len" and "sorted"
for bi in __builtins__.__dict__.keys():
	python_lexemes.add(bi)

# Get all operator text symbols, such as |=, ~, >>= etc.
operator_function_regex = re.compile(r"Same as (.+)\.")
non_word_regex = re.compile('[^\W\s]')

for name, val in operator.__dict__.items():
	if callable(val):
		try:
			operator_string = non_word_regex.sub('', operator_function_regex.findall(val.__doc__)[0] )
			for op in operator_string.split():
				python_lexemes.add(op)
		except:
			pass

# Symbols not in operator module :)
python_lexemes.add(":=") 
python_lexemes.add("'") 
python_lexemes.add('"') 
python_lexemes.add('"""') 


# Also satisfy all tokenizer cases (this will capture things like hex-numbers, bin-numbers, 
# and string prefixes like f,b,r, etc.)
from token import tok_name
CamelCaseRegex = re.compile(r'[A-Z][a-z]+[A-Z]*[a-z]*')

tokenize_dir = " ".join(dir(tokenize))

token_regex_strings = { t : getattr(tokenize, t) for t in CamelCaseRegex.findall(tokenize_dir) if isinstance(getattr(tokenize, t),str) }

# token_types =  set(tok_name.values())

# pangram_tokens = set()
# with open(PANGRAM_FILE, 'r') as pf:
# 	lines = " ".join([ str(l.strip()) for l in pf.readlines() ])
# 	lines = StringIO(lines)
# 	# for token in tokenize.generate_tokens(pf.readline):
# 	for token in tokenize.tokenize(lines.readlines):
# 	# for token in tokenize.tokenize(lambda : next(token_gen)):
# 		pangram_tokens.add(tok_name[token.type] )
# 		print(token)

####################################################################################################

# Get the lexemes from the file for evaluation of exhaustiveness

pangram_lexemes = set()

# quote_string_regex = re.compile(r"\"(\"\")?[^\"\{\}\n]*(\"\")?\"")
# apostrophe_string_regex = re.compile(r"'('')?[^'\{\}\n]*('')?'", flags=re.MULTILINE)

with open(PANGRAM_FILE, 'r') as pf:
	pangram_raw_body = pf.read()

pangram_body = pangram_raw_body
# Contents of strings do not count towards the goal :)
# pangram_body = quote_string_regex.sub('""', pangram_body)
# pangram_body = apostrophe_string_regex.sub("''", pangram_body)


for line in pangram_body.split():
	l = line.strip().partition('#')[0] # drop anything after a "#", i.e. ignore comments
	l = l.split()
	for t in l:
		pangram_lexemes.add(t)



####################################################################################################

# Run test suite to validate authenticity of pangram

import unittest
import trace
import sys
import runpy
import os


stdout_streams={}
stderr_streams={}

# Standard lib modules don't seem to expose a better API for capturing outputs to string
def capture_descriptor_output(f):
	def pipe_descriptor_to_stream_and_return(*args):
		global stdout_streams
		global stderr_streams 
		temp_out = StringIO() 
		temp_err = StringIO() 
		sys.stdout = temp_out 
		sys.stderr = temp_err 
		f(*args)
		sys.stdout = sys.__stdout__  
		sys.stderr = sys.__stderr__  
		stdout_streams[f.__name__] = temp_out.getvalue()
		stderr_streams[f.__name__] = temp_err.getvalue()
	return pipe_descriptor_to_stream_and_return



class TestPangramAuthenticity(unittest.TestCase):
	
	
	def assertSetComplete(self, truth, sample):
		self.assertSetEqual(truth, truth.intersection(sample))


	@capture_descriptor_output
	def test_pangram_runs_successfully(self): 
		global pangram_body
		try:

			module_name = PANGRAM_FILE.partition('.py')[0]
			mod_name, mod_spec, code = runpy._get_module_details(module_name)
			sys.argv = [code.co_filename]
			globs = {
					'__name__': '__main__',
					'__file__': code.co_filename,
					'__package__': mod_spec.parent,
					'__loader__': mod_spec.loader,
					'__spec__': mod_spec,
					'__cached__': None,
			}
			tracer = trace.Trace(ignoredirs=[sys.prefix, sys.exec_prefix], trace=1, count=1)
			code = compile(pangram_raw_body, PANGRAM_FILE, 'exec')
			tracer.runctx(code, globs,globs)
			tracer.results().write_results(show_missing=True, summary=False, coverdir=os.devnull)

		except Exception:
				self.fail("Pangram did not successfully execute")


	def test_pangram_has_all_python_lexemes(self):
		global pangram_body
		global python_lexemes
		# self.assertSetComplete(python_lexemes, pangram_lexemes)
		for l in python_lexemes:
			self.assertIn(l, pangram_body)


	def test_token_regex_machines_all_find_matches(self):
		global token_regex_strings
		global pangram_body
		for regex_name, regex in token_regex_strings.items():
			self.assertRegex(pangram_body, regex, msg=f"\n\t{regex_name}::::{regex} did not produce a match.")


	# def test_all_tokens_are_parsed_at_least_once(self):
	# 	global pangram_tokens
	# 	global token_types
	# 	self.assertSetComplete(token_types, pangram_tokens)



tests = ['assertAlmostEqual', 'assertAlmostEquals', 'assertCountEqual', 'assertDictContainsSubset', 'assertDictEqual', 'assertEqual', 'assertEquals', 'assertFalse', 'assertGreater', 'assertGreaterEqual', 'assertIn', 'assertIs', 'assertIsInstance', 'assertIsNone', 'assertIsNot', 'assertIsNotNone', 'assertLess', 'assertLessEqual', 'assertListEqual', 'assertLogs', 'assertMultiLineEqual', 'assertNotAlmostEqual', 'assertNotAlmostEquals', 'assertNotEqual', 'assertNotEquals', 'assertNotIn', 'assertNotIsInstance', 'assertNotRegex', 'assertNotRegexpMatches', 'assertRaises', 'assertRaisesRegex', 'assertRaisesRegexp', 'assertRegex', 'assertRegexpMatches', 'assertSequenceEqual', 'assertSetComplete', 'assertSetEqual', 'assertTrue', 'assertTupleEqual', 'assertWarns', 'assertWarnsRegex', 'assert_']


# @capture_descriptor_output
def main():
	# global stdout_streams
	# global stderr_streams 
	# temp_out = StringIO() 
	# temp_err = StringIO() 
	# sys.stdout = temp_out 
	# sys.stderr = temp_err 

	unittest.main(exit=False)


	# sys.stdout = sys.__stdout__  
	# sys.stderr = sys.__stderr__  
	# stdout_streams['main'] = temp_out.getvalue()
	# stderr_streams['main'] = temp_err.getvalue()


if __name__ == '__main__':
	main()
	for k,v in stdout_streams.items():
		print(f"{k} = {v}")